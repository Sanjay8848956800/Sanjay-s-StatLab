---
title: 20INMCAL204- Laboratory Report
author:
  - name: Sanjay Krishnan J
    email: sanjay.inmca@saintgits.org
    affiliation: Student, INMCA 20-25
    correspondingauthor: true
    footnote: 1
  - name: Siju K.S
    email: siju.swamy@saintgits.org
    affiliation: Saintgits College of Engineering (Autonomous)
    footnote: 2
  - name: Jobin Jose
    email: jobin.jose@saintgits.org
    affiliation: Saintgits College of Engineering (Autonomous)
    footnote: 2
address:
  - code: Student, INMCA 20-25
    address: Department of Computer Applications, RB402
  - code: Saintgits College of Engineering (Autonomous)
    address: Department of Mathematics, AB304
footnote:
  - code: 1
    text: "Student, 20INMCAL204."
  - code: 2
    text: "Course Faculty, 20INMCAL204."
abstract: |
 Experiments listed in the Lab Manual are successfully executed in the R version 4.1.0. Details of the experiments with input \& ouput are summerized in the form of a report. Experiments are arranged in the form of sections. This report is prepared using the R-package `rticles` [@mrticles].
journal: "Mathematics Department for Evaluation"
date: "`r Sys.Date()`"
classoption: preprint, 3p, authoryear
bibliography: mybibfile.bib
linenumbers: true
numbersections: true
# Use a CSL with `citation_package = "default"`
# csl: https://www.zotero.org/styles/elsevier-harvard
output: 
  rticles::elsevier_article:
    keep_tex: true
    citation_package: natbib
---
\tableofcontents
\newpage
# Experiment 4: Statistical Summary and measure of normality of a dataset

## Aim

1. To create the statistical summary of a data

2. To study normality of the data

## Packages used and syntax of R methods

For statistical summary of a given dataset, the `rbase` package will be used. To calculate skewness and kurtosis of dataset, the `ACSWR` is used.

>*Note:* The functions `skewness` and `kurtosis` from the `e1071` package are more generic functions. Another resouse is `moments` package. 

## Algorithm
* Step 1: Load the dataset

* Step 2: Load necessary packages

* Step 3: Calculate statistical summaries

* Step 4: Calculate the `skewness` and `kurtosis` of the numerical data

* Step 5: Report the results

## R code

```{r}
#loading package
library(ACSWR)
#loading data
data(yb)
#view structure of data
str(yb)

```
```{r}
# creating statistical summary

summary(yb)
```
```{r}
range(yb$Preparation_1); range(yb$Preparation_2) # list out ranges of data

```

```{r}
#skewness and kurtosis of preparation_1
skewcoeff(yb$Preparation_1); kurtcoeff(yb$Preparation_1)
```
```{r}
#skewness and kurtosis of preparation_2
skewcoeff(yb$Preparation_2); kurtcoeff(yb$Preparation_2)
```

## Results & discussions

A distribution is normal then `mean=median=mode` and the skewness is 0 and kurtosis is 2. In this experiment statistical summaries of two variables are created. From the skewness and kurtosis measures, both the variables are positively skewed and `preparation_1` is lepto-kurtic and `preparation_2` is meso-kurtic. Based on the statistical summary and skewness and kurtosis measures, both the variables are different from a normal distribution.

# Experiment 5- Implementation of Bayes Theorem

## Aim

1. To calculate Bayes posterior probability using Bayes theorem

## Packages used and syntax of R methods

Bayes posterior probability can be directly calculated using mathematical method or using the package `LaplacesDemon`.

## Algorithm
* Step 1: Load the package, prior probabilities and conditionals

* Step 2: Calculate the Bayes posterior probability using the formula-$P(B_j|A)=\dfrac{P(A|B_j)P(B_j)}{\sum\limits_{j=1}^mP(A|B_j)P(B_j)}$

* Step 3: Calculate the same prior probability using `LaplaceDemon` package

* Step 4: Report the results

>*Case:* Classical Problem from Hoel, Port, and Stone (1971). Suppose there are three tables with two drawers each. The first table has a gold coin in each of the drawers, the second table has a gold coin in one drawer and a silver coin in the other drawer, while the third table has silver coins in both of the drawers. A table is selected at random and a drawer is opened which shows a gold coin. 

>*Observation:*The problem is to compute the probability of the other drawer also showing a gold coin. The Bayes formula can be easily implemented in an R program.

## R code

```{r}
#loading data
prob_GC <- c(1,1/2,0)
priorprob_GC <- c(1/3,1/3,1/3)
```

```{r}
#calculating postrior probability
post_GC <- prob_GC*priorprob_GC
post_GC/sum(post_GC)
```

```{r}
# do the same using LaplacesDemon` package
library(LaplacesDemon)
BayesTheorem(prob_GC, priorprob_GC)

```


## Results & discussions

The Bayes theorem is used to calculate posterior probability of the Mathematical model of the given case. Also the result is verified using the `LaplacesDemon` package.


\hrule

# References {.unnumbered}

# Experiment -2 implement various EDA techniques using R.

##Aim
implement various EDA techniques using R.

##Algorithm

**step1:**Create R-code chunks for coding

**step 2:**Create a Boxplot using built -in dataset

**step3:**Create a Histogram using R

**step 4:**create a Scatter plot using R

**step 5:**Create a Running chart/time series plot using R

##R-code

### Boxplot
The Youden-Beale Experiment. We have used this dataset in Chapter 2, Section 4, and in a few other places too. We need to compare here if the two virus extracts have a varying effect on the tobacco leaf or not. We have already read this dataset into R on more than one occasion. First, the boxplot is generated without the notches for yb data.frame using the boxplot function. The median for `Preparation_1` certainly appears higher than for `Preparation_2`, see Part A of Figure 3.1. Thus, we are tempted to check whether the medians for the two preparations are significantly different with the notched boxplot. Now, the boxplot is generated to produce the notches with the option notch=TRUE. Appropriate headers for a figure are specified with the title function. Most importantly, we have used a powerful graphical technique of R through par, which is useful in setting graphical parameters. Here, mfrow indicates that we need a multi-row figure with one row and two columns(Tattar 2015).

```{r,warning=FALSE}
library(ACSWR)
data(yb)
par(mfrow=c(1,2))
boxplot(yb)
title("A: Boxplot for Youden-Beale Data")
boxplot(yb,notch=TRUE)
title("B: Notched Boxplots Now")

```
```{r}
summary(yb$Preparation_1)
```
```{r}
summary(yb$Preparation_2)
```
### Histogram:

The histogram was invented by the eminent statistician Karl Pearson and is one of the earliest types of graphical display. It goes without saying that its origin is earlier than EDA, at least the EDA envisioned by Tukey, and yet it is considered by many EDA experts to be a very useful graphical technique, and makes it to the list of one of the very useful practices of EDA. The basic idea is to plot a bar over an interval proportional to the frequency of the observations that lie in that interval. If the sample size is moderately good in some sense and the sample is a true representation of a population, the histogram reveals the shape of the true underlying uncertainty curve. Though histograms are plotted as two-dimensional, they are essentially one-dimensional plots in the sense that the shape of the uncertainty curve is revealed without even looking at the range of the x-axis. Furthermore, the Pareto chart, stem-and-leaf plot, and a few others may be shown as special cases of the histogram.We begin with a “cooked” dataset for understanding a range of uncertainty curves.

Understanding Histogram of Various Uncertainty Curves. In the dataset sample, we have data from five different probability distributions. Towards understanding the plausible distribution of the samples, we plot the histogram and see how useful it is.


```{r}
data(sample)
layout(matrix(c(1,1,2,2,3,3,0,4,4,5,5,0), nrow=2, ncol=6, byrow=TRUE),respect=FALSE)
#matrix(c(1,1,2,2,3,3,0,4,4,5,5,0), nrow=2, ncol=6, byrow=TRUE)
hist(sample[,1],main="Histogram of Sample 1",xlab="sample1",  ylab="frequency")
hist(sample[,2],main="Histogram of Sample 2",xlab="sample2", ylab="frequency")
hist(sample[,3],main="Histogram of Sample 3",xlab="sample3", ylab="frequency")
hist(sample[,4],main="Histogram of Sample 4",xlab="sample4", ylab="frequency")
hist(sample[,5],main="Histogram of Sample 5",xlab="sample5", ylab="frequency")
```
### Histogram extensions:
Understanding Histogram of Various Uncertainty Curves. The short program for this problem is given below.
```{r}
library(sfsmisc)
par(mfrow=c(1,3))
histBxp(sample$Sample_1,col="blue",boxcol="blue",xlab="x")
histBxp(sample$Sample_2,col="grey",boxcol="grey",xlab="x")
histBxp(sample$Sample_3,col="brown",boxcol="brown",xlab="x")
title("Boxplot and Histogram Complementing",outer=TRUE,line=-1)

```

### Parto chart theory :
Pareto Chart
The Pareto chart has been designed to address the implicit questions answered by the Pareto law. The common understanding of the Pareto law is that “majority resources” is consumed by a “minority user.” The most common of the percentages is the 80–20 rule, implying that 80% of the effects come from 20% of the causes. The Pareto law is also known as the law of vital few, or the 80–20 rule. The Pareto chart gives very smart answers by completely answering how much is owned by how many. Montgomery (2005), page 148, has listed the Pareto chart as one of the seven major tools of Statistical Process Control.

A Pareto chart is a bar graph. The lengths of the bars represent frequency or cost (time or money), and are arranged with longest bars on the left and the shortest to the right. In this way the chart visually depicts which situations are more significant. This cause analysis tool is considered one of the seven basic quality tools 
```{r}
library(qcc)
freq <- c(14,2,1,2,3,8,1)
names(freq) <- c("Contamination","Corrosion","Doping", "Metallization", "Miscellaneous", "Oxide Effect","Silicon Effect")
pareto.chart(freq)
```

##Result & Discussions
various visualization techniques for data analysis are implemented in R.

#Experiment 3 
## Aim

To administer baseline statistical analysis on a dataset and report descriptive analysis summary.


## Algorithm

* Step-1: Load the data and required R-packages for data analysis

* Step-2: Apply basic statistic functions 

* Step-3: Create appropriate visualizations

* Step-4: Report the findings based on descriptive analysis

## R-code

>Loading data

```{r}
df<-read.csv("https://raw.githubusercontent.com/sijuswamy/StatLab/main/Dataset_1.csv",header = TRUE)
df$Gender=as.factor(df$Gender)

head(df)
```

```{r}
str(df)
```
> Finding Column sums

```{r,warning=FALSE}
library(dplyr)
df1=select(df,-Student_Name,-Gender)
Sub_total=colSums(df1)
Sub_average=colMeans(df1)
```
```{r}
round(Sub_average,2)
```
```{r}
library(ggplot2)
crop=ggplot(data=df, mapping=aes(x=Gender, y=X20IMCAT201))+geom_boxplot()+labs(x ="Gender", y = "Maths")
crop
```

```{r}
ggplot(data = df, aes(x = X20IMCAT201,fill = df$Gender)) + geom_histogram(binwidth = 15, fill = "seagreen",color = "red")+ 
  theme(legend.position = "top")#+facet_grid(~Gender)

```
```{r}
plot(density(df$X20IMCAT201))
```


```{r}
median(df$X20IMCAT201)
```



```{r}
library(DescTools)
Mode(df$X20IMCAT201)
```
>User defined funtion


```{r}
calcmode <- function(a) {  
vector <- unique(a)  
vector[which.max(tabulate(match(a, vector)))]  
}  
```
```{r}
calcmode(df$X20IMCAT201)
```
```{r}
sd(df$X20IMCAT201)
```


## Results and discussions

#experiment 4

## Aim

1. To create the statistical summary of a data

2. To study normality of the data

## Packages used and syntax of R methods

For statistical summary of a given dataset, the `rbase` package will be used. To calculate skewness and kurtosis of dataset, the `ACSWR` is used.

>*Note:* The functions `skewness` and `kurtosis` from the `e1071` package are more generic functions. Another resouse is `moments` package. 

## Algorithm
* Step 1: Load the dataset

* Step 2: Load necessary packages

* Step 3: Calculate statistical summaries

* Step 4: Calculate the `skewness` and `kurtosis` of the numerical data

* Step 5: Report the results

## R code

```{r}
#loading package
library(ACSWR)
#loading data
data(yb)
#view structure of data
str(yb)

```
```{r}
# creating statistical summary

summary(yb)
```
```{r}
range(yb$Preparation_1); range(yb$Preparation_2) # list out ranges of data

```

```{r}
#skewness and kurtosis of preparation_1
skewcoeff(yb$Preparation_1); kurtcoeff(yb$Preparation_1)
```
```{r}
#skewness and kurtosis of preparation_2
skewcoeff(yb$Preparation_2); kurtcoeff(yb$Preparation_2)
```

## Results & discussions

A distribution is normal then `mean=median=mode` and the skewness is 0 and kurtosis is 2. In this experiment statistical summaries of two variables are created. From the skewness and kurtosis measures, both the variables are positively skewed and `preparation_1` is lepto-kurtic and `preparation_2` is meso-kurtic. Based on the statistical summary and skewness and kurtosis measures, both the variables are different from a normal distribution.
#Experiment 5
## Aim

1. To calculate Bayes posterior probability using Bayes theorem

## Packages used and syntax of R methods

Bayes posterior probability can be directly calculated using mathematical method or using the package `LaplacesDemon`.

## Algorithm
* Step 1: Load the package, prior probabilities and conditionals

* Step 2: Calculate the Bayes posterior probability using the formula-$P(B_j|A)=\dfrac{P(A|B_j)P(B_j)}{\sum\limits_{j=1}^mP(A|B_j)P(B_j)}$

* Step 3: Calculate the same prior probability using `LaplaceDemon` package

* Step 4: Report the results

>*Case:* Classical Problem from Hoel, Port, and Stone (1971). Suppose there are three tables with two drawers each. The first table has a gold coin in each of the drawers, the second table has a gold coin in one drawer and a silver coin in the other drawer, while the third table has silver coins in both of the drawers. A table is selected at random and a drawer is opened which shows a gold coin. 

>*Observation:*The problem is to compute the probability of the other drawer also showing a gold coin. The Bayes formula can be easily implemented in an R program.

## R code

```{r}
#loading data
prob_GC <- c(1,1/2,0)
priorprob_GC <- c(1/3,1/3,1/3)
```

```{r}
#calculating postrior probability
post_GC <- prob_GC*priorprob_GC
post_GC/sum(post_GC)
```

```{r}
# do the same using LaplacesDemon` package
library(LaplacesDemon)
BayesTheorem(prob_GC, priorprob_GC)

```


## Results & discussions

The Bayes theorem is used to calculate posterior probability of the Mathematical model of the given case. Also the reslut is verified using the `LaplacesDemon` package.
#Experiment 6
## Aim

1. To calculate probability mass density, probability distribution and quantiles using binomial distribution

## Packages used and syntax of R methods

Functions from `stat` package (which is loaded by default). 

The probability mass at a point $x$ can be evaluated using the syntax:

>`dbinom(x=x,size=n,p=p)`.

The probability distribution $P(X\leq x)$ is calculated using the `pbinom()` function. Syntax is: 

>`pbinom(x,size=n,p=p)`

The quantile for probability $p$ can be evaluated using the `quantile()` function. Syntax is:

>`qbinom(prob,size,p=p)`

## Algorithm

* Step 1: Assign the inputs for required distribution

* Step 2: Calculate the required probabilities

* Step 3: Report the results


>*Case:* Find the mass function of a binomial distribution with  $n=20,p=0.4$. Also draw the graphs of the mass function and cumulative distribution function.

## R code

```{r}
# create input parameters
n=20
p=0.4
x=0:20
```
### Prbability distribution

```{r}
#calculating probability mass distribution and cumulative distribution
pmval=dbinom(x,size=n,prob=p)
pmval
```

## Cumulative probability distribution

```{r}
#calculating cumulative density
cdval=pbinom(x,size=n,prob=p)
cdval
```
### Plotting the `pmf` and `cdf`

```{r}
par(mfrow=c(1,2))
plot(x,pmval,xlab="x",ylab="P(X=x)", main="The Binomial Distribution")
plot(x,cdval,xlab="x",ylab=expression(P(X<=x)),main="Cumulative Distribution Function")

```


## Results & discussions

The `pmf` and `cf` of the Binomial distribution for given input parameters are evaluated and create respective plots.